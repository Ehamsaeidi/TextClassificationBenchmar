{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3a1a35f-9f58-4228-ae5b-dc18dc694df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "249595d9-2337-4044-a887-3e0e8b13c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load 20 Newsgroups Dataset\n",
    "\n",
    "data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "150bfbd2-ddde-4009-8a8d-80e57648f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "vectorizers = {\n",
    "    \"CountVectorizer\": CountVectorizer(),\n",
    "    \"TF-IDF\": TfidfVectorizer()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9387233-c6be-4714-a56d-1dfe3832eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "815ef7f5-2628-455f-91f0-a70e33428969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking Models with Different Feature Extractors\n",
    "results = []\n",
    "\n",
    "for vect_name, vectorizer in vectorizers.items():\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results.append({\n",
    "            \"Feature Extractor\": vect_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": round(acc * 100, 2)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfbe4c01-e2dc-4374-91ef-6f80d03da7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extractor               Model  Accuracy\n",
      "           TF-IDF                 SVM     90.64\n",
      "           TF-IDF Logistic Regression     89.39\n",
      "  CountVectorizer Logistic Regression     88.54\n",
      "  CountVectorizer         Naive Bayes     85.12\n",
      "           TF-IDF         Naive Bayes     84.75\n",
      "  CountVectorizer       Decision Tree     64.40\n",
      "           TF-IDF       Decision Tree     61.80\n",
      "  CountVectorizer                 SVM     35.89\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "print(df_results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f3a5f06-9fa7-459c-aa85-1a07cadc65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 20 Newsgroups Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the training and test data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_train_raw = newsgroups_train.data\n",
    "X_test_raw = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8eec8167-1d90-44c7-92a3-9e0eb0f86da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Extraction with CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "X_train_count = count_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_count = count_vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d3fdda89-747d-434a-b23b-7ea8f293303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize documents\n",
    "def tokenize(doc):\n",
    "    return [word for word in doc.lower().split() if len(word) > 2]\n",
    "\n",
    "tokenized_docs_train = [tokenize(doc) for doc in X_train_raw]\n",
    "tokenized_docs_test = [tokenize(doc) for doc in X_test_raw]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_docs_train, vector_size=100, window=5, min_count=5)\n",
    "\n",
    "# Function to get document vector (mean of word vectors)\n",
    "def document_vector(doc):\n",
    "    vectors = [w2v_model.wv[word] for word in doc if word in w2v_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "X_train_w2v = np.array([document_vector(doc) for doc in tokenized_docs_train])\n",
    "X_test_w2v = np.array([document_vector(doc) for doc in tokenized_docs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3750aac2-2da4-41b2-a6e9-a62cbc01a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Tag documents for Doc2Vec\n",
    "train_tagged = [TaggedDocument(words=doc, tags=[i]) for i, doc in enumerate(tokenized_docs_train)]\n",
    "test_tagged = [TaggedDocument(words=doc, tags=[i]) for i, doc in enumerate(tokenized_docs_test)]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "d2v_model = Doc2Vec(vector_size=100, window=5, min_count=5, epochs=20)\n",
    "d2v_model.build_vocab(train_tagged)\n",
    "d2v_model.train(train_tagged, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "# Get vectors\n",
    "X_train_d2v = np.array([d2v_model.dv[i] for i in range(len(train_tagged))])\n",
    "X_test_d2v = np.array([d2v_model.infer_vector(doc.words) for doc in test_tagged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2144ea9d-5eb5-4635-af9d-6220067f0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "# Define a function to train and evaluate\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name, feature_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results.append((feature_name, model_name, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "deabc2f3-6097-4aad-a788-6b9977ee2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elham\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\elham\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#For CountVectorizer:\n",
    "evaluate_model(MultinomialNB(), X_train_count, y_train, X_test_count, y_test, 'Naive Bayes', 'CountVectorizer')\n",
    "\n",
    "evaluate_model(LogisticRegression(max_iter=3000, solver='saga'), X_train_count, y_train, X_test_count, y_test, 'Logistic Regression', 'CountVectorizer')\n",
    "\n",
    "evaluate_model(LinearSVC(max_iter=3000), X_train_count, y_train, X_test_count, y_test, 'SVM', 'CountVectorizer')\n",
    "\n",
    "evaluate_model(DecisionTreeClassifier(), X_train_count, y_train, X_test_count, y_test, 'Decision Tree', 'CountVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be555666-6fa1-4a1e-9e70-c916db670dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "# For TF-IDF:\n",
    "evaluate_model(MultinomialNB(), X_train_tfidf, y_train, X_test_tfidf, y_test, 'Naive Bayes', 'TF-IDF')\n",
    "evaluate_model(LogisticRegression(max_iter=1000), X_train_tfidf, y_train, X_test_tfidf, y_test, 'Logistic Regression', 'TF-IDF')\n",
    "evaluate_model(LinearSVC(), X_train_tfidf, y_train, X_test_tfidf, y_test, 'SVM', 'TF-IDF')\n",
    "evaluate_model(DecisionTreeClassifier(), X_train_tfidf, y_train, X_test_tfidf, y_test, 'Decision Tree', 'TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "391587df-cea7-4a15-bf82-35b1ed5f0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Word2Vec & Doc2Vec (No Naive Bayes because it's not compatible with negative values)\n",
    "for feature_name, X_train_feat, X_test_feat in [('Word2Vec', X_train_w2v, X_test_w2v), ('Doc2Vec', X_train_d2v, X_test_d2v)]:\n",
    "    evaluate_model(LogisticRegression(max_iter=1000), X_train_feat, y_train, X_test_feat, y_test, 'Logistic Regression', feature_name)\n",
    "    evaluate_model(LinearSVC(), X_train_feat, y_train, X_test_feat, y_test, 'SVM', feature_name)\n",
    "    evaluate_model(DecisionTreeClassifier(), X_train_feat, y_train, X_test_feat, y_test, 'Decision Tree', feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "32650ece-227d-49d1-8780-ea2e9c7f79a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature                Model  Accuracy\n",
      "0   CountVectorizer          Naive Bayes  0.594663\n",
      "1   CountVectorizer  Logistic Regression  0.433617\n",
      "2   CountVectorizer                  SVM  0.552974\n",
      "3   CountVectorizer        Decision Tree  0.436272\n",
      "4   CountVectorizer          Naive Bayes  0.594663\n",
      "5   CountVectorizer  Logistic Regression  0.433617\n",
      "6   CountVectorizer                  SVM  0.552974\n",
      "7   CountVectorizer        Decision Tree  0.442379\n",
      "8            TF-IDF          Naive Bayes  0.650558\n",
      "9            TF-IDF  Logistic Regression  0.647637\n",
      "10           TF-IDF                  SVM  0.627058\n",
      "11           TF-IDF        Decision Tree  0.434413\n",
      "12         Word2Vec  Logistic Regression  0.317578\n",
      "13         Word2Vec                  SVM  0.338821\n",
      "14         Word2Vec        Decision Tree  0.169012\n",
      "15          Doc2Vec  Logistic Regression  0.467207\n",
      "16          Doc2Vec                  SVM  0.420738\n",
      "17          Doc2Vec        Decision Tree  0.177111\n"
     ]
    }
   ],
   "source": [
    "#creat table\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['Feature', 'Model', 'Accuracy'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "071fd6c5-9e38-40c5-a9e8-6da4390d8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"ElhamSaeidi_Task0_Text_Classification.txt\", index=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ee1ab70d-da8f-42a3-a7fa-079a2b26f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\elham\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\elham\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\elham\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n",
    "from docx import Document\n",
    "doc = Document()\n",
    "doc.add_heading('Text Classification Benchmark Results', 0)\n",
    "table = doc.add_table(rows=1, cols=3)\n",
    "table.style = 'Table Grid'\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'Feature'\n",
    "hdr_cells[1].text = 'Model'\n",
    "hdr_cells[2].text = 'Accuracy (%)'\n",
    "for index, row in df_results.iterrows():\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = str(row['Feature'])\n",
    "    row_cells[1].text = str(row['Model'])\n",
    "    row_cells[2].text = f\"{row['Accuracy']:.2f}\"\n",
    "doc.save(\"ElhamSaeidi2_Task0_Text_Classification.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac82956-818f-4fe8-8557-5fde7075fccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
